{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Spam/Ham Classification\n",
    "## Classifiers\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the project, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** at the top\n",
    "of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version already downloaded: Sat Apr 25 12:08:27 2020\n",
      "MD5 hash of file: 0380c4cf72746622947b9ca5db9b8be8\n",
      "Using version already downloaded: Sat Apr 25 12:08:28 2020\n",
      "MD5 hash of file: a2e7abd8c7d9abf6e6fafc1d1f9ee6bf\n"
     ]
    }
   ],
   "source": [
    "from utils import fetch_and_cache_gdrive\n",
    "fetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\n",
    "fetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n",
    "\n",
    "original_training_data = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Convert the emails to lower case as a first step to processing the text\n",
    "original_training_data['email'] = original_training_data['email'].str.lower()\n",
    "test['email'] = test['email'].str.lower()\n",
    "\n",
    "original_training_data.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(original_training_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is adapted from Part A of this project. You will be using it again in Part B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]]), array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    '''\n",
    "    Args:\n",
    "        words (list-like): words to find\n",
    "        texts (Series): strings to search in\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
    "        number of texts and p is the number of words.\n",
    "    '''\n",
    "    indicator_array = 1 * np.array([texts.str.contains(word) for word in words]).T\n",
    "    return indicator_array\n",
    "\n",
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = words_in_texts(some_words, train['email']) \n",
    "Y_train = np.array(train['spam'])\n",
    "\n",
    "X_train[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you trained the following model in Part A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7576201251164648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model =  LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "training_accuracy = model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model you trained doesn't seem too shabby! But the classifier you made above isn't as good as this might lead us to believe. First, we are evaluating accuracy on the training set, which may provide a misleading accuracy measure, especially if we used the training set to identify discriminative features. In future parts of this analysis, it will be safer to hold out some of our data for model validation and comparison.\n",
    "\n",
    "Presumably, our classifier will be used for **filtering**, i.e. preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
    "- False positive (FP): a ham email gets flagged as spam and filtered out of the inbox.\n",
    "- False negative (FN): a spam email gets mislabeled as ham and ends up in the inbox.\n",
    "\n",
    "These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier, in addition to overall accuracy:\n",
    "\n",
    "**Precision** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ of emails flagged as spam that are actually spam.\n",
    "\n",
    "**Recall** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ of spam emails that were correctly flagged as spam. \n",
    "\n",
    "**False-alarm rate** measures the proportion $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$ of ham emails that were incorrectly flagged as spam. \n",
    "\n",
    "The following image might help:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"500px\">\n",
    "\n",
    "Note that a true positive (TP) is a spam email that is classified as spam, and a true negative (TN) is a ham email that is classified as ham."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Suppose we have a classifier `zero_predictor` that always predicts 0 (never predicts positive). How many false positives and false negatives would this classifier have if it were evaluated on the training set and its results were compared to `Y_train`? Fill in the variables below (answers can be hard-coded):\n",
    "\n",
    "*Tests in Question 6 only check that you have assigned appropriate types of values to each response variable, but do not check that your answers are correct.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_predictor_fp = 0 # FP & TP will always be 0 (never considered spam)\n",
    "zero_predictor_fn = train['spam'].sum() # mislabeled as ham FN, correcly labeled as ham TN, where TN = tot_rows - zero_predictor_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q6a\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### What are the accuracy and recall of `zero_predictor` (classifies every email as ham) on the training set? Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7447091707706642"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_predictor_acc = (0 + len(train) - zero_predictor_fn) / len(train) # TP + TN / ALL ROWS\n",
    "zero_predictor_recall = 0 # (TP / TP + FN) , bc TP = 0 , then (0 / 0 + zero_predictor_fn) = 0\n",
    "zero_predictor_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 2\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q6b\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Provide brief explanations of the results from 6a and 6b. Explain why the number of false positives, number of false negatives, accuracy, and recall all turned out the way they did.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "manual: True\n",
    "points: 2\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our predictor always marks our emails as ham, the **True Positive** and **False Positive** will always be 0, because again, our predictor will not help us detect spam. This means that the **False Negatives** will be all those emails that are actualy spam, but considered as ham, and the **True Negative** will be all those emails that are actually ham. **Accuracy** will be all those emails that are correctly labeled; we know that our True Positive will always be 0, leaving us with only the True Negatives (which are all the actual ham emails), over the total number of emails. Finally, **Recall** is 0, as our predictor will always  yield a True Positive value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>7657</td>\n",
       "      <td>Subject: Patch to enable/disable log\\n</td>\n",
       "      <td>while i was playing with the past issues, it a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>6911</td>\n",
       "      <td>Subject: When an engineer flaps his wings\\n</td>\n",
       "      <td>url: http://diveintomark.org/archives/2002/10/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>6074</td>\n",
       "      <td>Subject: Re: [Razor-users] razor plugins for m...</td>\n",
       "      <td>no, please post a link!\\n \\n fox\\n ----- origi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>4376</td>\n",
       "      <td>Subject: NYTimes.com Article: Stop Those Press...</td>\n",
       "      <td>this article from nytimes.com \\n has been sent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>5766</td>\n",
       "      <td>Subject: What's facing FBI's new CIO? (Tech Up...</td>\n",
       "      <td>&lt;html&gt;\\n &lt;head&gt;\\n &lt;title&gt;tech update today&lt;/ti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            subject  \\\n",
       "7657  7657             Subject: Patch to enable/disable log\\n   \n",
       "6911  6911        Subject: When an engineer flaps his wings\\n   \n",
       "6074  6074  Subject: Re: [Razor-users] razor plugins for m...   \n",
       "4376  4376  Subject: NYTimes.com Article: Stop Those Press...   \n",
       "5766  5766  Subject: What's facing FBI's new CIO? (Tech Up...   \n",
       "\n",
       "                                                  email  spam  \n",
       "7657  while i was playing with the past issues, it a...     0  \n",
       "6911  url: http://diveintomark.org/archives/2002/10/...     0  \n",
       "6074  no, please post a link!\\n \\n fox\\n ----- origi...     0  \n",
       "4376  this article from nytimes.com \\n has been sent...     0  \n",
       "5766  <html>\\n <head>\\n <title>tech update today</ti...     0  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Compute the precision, recall, and false-alarm rate of the `LogisticRegression` classifier created and trained in Part A. Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "**Note: In lecture we used the `sklearn` package to compute the rates. Here you should work through them using just the definitions to help build a deeper understanding.**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat = model.predict(X_train)\n",
    "logistic_predictor_precision = np.sum((Y_train_hat == 1) & (Y_train == 1)) / np.sum(Y_train_hat) # TP /TP + FP\n",
    "logistic_predictor_recall = np.sum((Y_train_hat == 1) & (Y_train == 1)) / np.sum(Y_train) # TP / TP + FN\n",
    "logistic_predictor_far = np.sum((Y_train_hat == 1) & (Y_train == 0)) / (np.sum((Y_train_hat == 1) & (Y_train == 0)) + np.sum((Y_train_hat == 0) & (Y_train == 0))) # FP / FP +TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running tests\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Test summary\n",
      "    Passed: 3\n",
      "    Failed: 0\n",
      "[ooooooooook] 100.0% passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ok.grade(\"q6d\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Are there more false positives or false negatives when using the logistic regression classifier from Part A?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6e\n",
    "manual: True\n",
    "points: 1\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more false negatives as our logistic regression classifier still needs to  be improved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "1699\n"
     ]
    }
   ],
   "source": [
    "FP =  np.sum((Y_train_hat == 1) & (Y_train == 0))\n",
    "FN =  np.sum((Y_train_hat == 0) & (Y_train == 1))\n",
    "\n",
    "print(FP) # Ham marked as Spam\n",
    "print(FN) # Spam marked as Ham"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### \n",
    "\n",
    "1. Our logistic regression classifier got 75.8% prediction accuracy (number of correct predictions / total). How does this compare with predicting 0 for every email?\n",
    "1. Given the word features we gave you above, name one reason this classifier is performing poorly. Hint: Think about how prevalent these words are in the email set.\n",
    "1. Which of these two classifiers would you prefer for a spam filter and why? Describe your reasoning and relate it to at least one of the evaluation metrics you have computed so far.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6f\n",
    "manual: True\n",
    "points: 3\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Our logistic regression currently is slightly better at filtering which emails are spam and ham than the zero predictor, with a 75.8 compared to 74.4 \n",
    "2. The words in our list some_words might not be good for our regression as it could be the case that they are not highly present in either sets of emails (spam or ham), therefore they would not be good indicators of what type of email we are looking at if they are not representative of either.\n",
    "3. As of right now, I would prefer the zero predictor because it has 0 for False Positive, meaning that all of the ham would be delivered correctly, whereas our Logistic Regression model has a total of 122 hams that would have been sent to spam. The importance of each email is what makes us prefer a model with less accuracy but with lower danger of missing a crucial Ham.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Forward\n",
    "\n",
    "With this in mind, it is now your task to make the spam filter more accurate. In order to get full credit on the accuracy part of this assignment, you must get at least **88%** accuracy on the test set. To see your accuracy on the test set, you will use your classifier to predict every email in the `test` DataFrame and upload your predictions to Kaggle.\n",
    "\n",
    "**Kaggle limits you to four submissions per day**. This means you should start early so you have time if needed to refine your model. You will be able to see your accuracy on the entire set when submitting to Kaggle (the accuracy that will determine your score for question 9).\n",
    "\n",
    "Here are some ideas for improving your model:\n",
    "\n",
    "1. Finding better features based on the email text. Some example features are:\n",
    "    1. Number of characters in the subject / body\n",
    "    1. Number of words in the subject / body\n",
    "    1. Use of punctuation (e.g., how many '!' were there?)\n",
    "    1. Number / percentage of capital letters \n",
    "    1. Whether the email is a reply to an earlier email or a forwarded email\n",
    "1. Finding better (and/or more) words to use as features. Which words are the best at distinguishing emails? This requires digging into the email text itself. \n",
    "1. Better data processing. For example, many emails contain HTML as well as text. You can consider extracting out the text from the HTML to help you find better words. Or, you can match HTML tags themselves, or even some combination of the two.\n",
    "1. Model selection. You can adjust parameters of your model (e.g. the regularization parameter) to achieve higher accuracy. Recall that you should use cross-validation to do feature and model selection properly! Otherwise, you will likely overfit to your training data.\n",
    "\n",
    "You may use whatever method you prefer in order to create features, but **you are not allowed to import any external feature extraction libraries**. In addition, **you are only allowed to train logistic regression models**. No random forests, k-nearest-neighbors, neural nets, etc.\n",
    "\n",
    "We have not provided any code to do this, so feel free to create as many cells as you need in order to tackle this task. However, answering questions 7, 8, and 9 should help guide you.\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fresh bread out of the oven\n",
    "training_data = pd.read_csv('data/train.csv')\n",
    "\n",
    "training, validation = train_test_split(training_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/data100/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>spesh chars</th>\n",
       "      <th>chars in email</th>\n",
       "      <th>chars in sub</th>\n",
       "      <th># of uppercase in email</th>\n",
       "      <th>reply?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1641</td>\n",
       "      <td>37</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4713</td>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4435</td>\n",
       "      <td>73</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32857</td>\n",
       "      <td>52</td>\n",
       "      <td>1366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>465</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7509</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>7054</td>\n",
       "      <td>42</td>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7510</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1732</td>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>1098</td>\n",
       "      <td>52</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>812</td>\n",
       "      <td>61</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7513 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  76  77  78  79  80  spesh chars  \\\n",
       "0     0  0  0  0  0  1  1  1  0  0  ...   0   0   0   0   1         17.0   \n",
       "1     0  0  1  1  1  1  0  1  0  0  ...   1   0   1   0   1         22.0   \n",
       "2     0  0  0  0  0  1  1  1  0  0  ...   0   0   0   0   1         48.0   \n",
       "3     0  0  1  0  1  1  1  1  0  0  ...   0   0   0   0   1         38.0   \n",
       "4     0  1  1  1  0  1  1  1  0  0  ...   1   0   1   0   1         64.0   \n",
       "...  .. .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..          ...   \n",
       "7508  0  0  0  0  1  0  0  0  0  0  ...   0   0   0   0   0         19.0   \n",
       "7509  0  0  0  0  0  1  1  1  0  0  ...   0   1   1   0   1         77.0   \n",
       "7510  0  0  0  1  0  0  1  1  0  0  ...   0   0   0   0   0         63.0   \n",
       "7511  0  0  0  0  0  1  0  1  0  0  ...   0   0   0   0   0       2084.0   \n",
       "7512  0  0  0  0  0  0  1  1  0  0  ...   0   0   0   0   0         52.0   \n",
       "\n",
       "      chars in email  chars in sub  # of uppercase in email  reply?  \n",
       "0               1641            37                       69       0  \n",
       "1               4713            42                       90       0  \n",
       "2               1399            54                       51       1  \n",
       "3               4435            73                      188       0  \n",
       "4              32857            52                     1366       0  \n",
       "...              ...           ...                      ...     ...  \n",
       "7508             465            60                       21       0  \n",
       "7509            7054            42                      908       0  \n",
       "7510            1732            26                       64       0  \n",
       "7511            1098            52                       33       1  \n",
       "7512             812            61                       24       1  \n",
       "\n",
       "[7513 rows x 86 columns]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training['subject'] = training[\"subject\"].apply(str)\n",
    "\n",
    "#1\n",
    "#Number of characters in the subject / body\n",
    "single_sub = [sub for sub in training['subject']]\n",
    "single_email = [sentence for sentence in training['email']]\n",
    "\n",
    "chars_em = [len(a) for a in single_email]\n",
    "chars_sub = [len(a) for a in single_sub]\n",
    "\n",
    "#Number of words in the subject / body\n",
    "num_words_em = training['email'].apply(len)\n",
    "num_words_sub = training['subject'].apply(len)\n",
    "\n",
    "\n",
    "#Use of punctuation (e.g., how many '!' were there?)\n",
    "spesh_char = training['email'].str.findall('[!&.?\":,|<>]').apply(len).astype(object)\n",
    "\n",
    "\n",
    "#Number / percentage of capital letters\n",
    "upper_em = [sum([c.isupper() for c in a]) for a in single_email]\n",
    "#upper_sub = [sum([c.isupper() for c in a]) for a in single_sub]\n",
    "\n",
    "\n",
    "#Whether the email is a reply to an earlier email or a forwarded email\n",
    "replies = []\n",
    "for sub in training[\"subject\"]:\n",
    "    if \"Re:\" in sub:\n",
    "        replies.append(1)\n",
    "    elif \"RE:\" in sub:\n",
    "        replies.append(1)\n",
    "    else:\n",
    "        replies.append(0)\n",
    "\n",
    "\n",
    "#2\n",
    "some_other_words = ['apple', 'interview','html','body','first', 'new', '!', '1', 'selected',\n",
    "                    'millionth', 'winner', 'are','...', '$', 'P.S.', 'warning', 'attention',\n",
    "                    'free','FREE', 'limited','exclusive','promo', 'offer', 'act', 'now', '.', 'adult', 'Adult'\n",
    "                   'membership', '<head>', '<body>', '<>', '<html>', '</head>', '<center>', '<h1>', 'table', '\\n',\n",
    "                   'drug', 'keto','prescription', 'cannabis', 'weight', 'loss', 'pay', 'enhance', 'performance', \n",
    "                   'hard', 'money', 'congratulations', 'pain', 'stop', 'access', '<blockquote>', 'male', 'female', 'enhancer', \n",
    "                   'site', 'treatment', 'the', 'you','your','this', 'fat', 'burn', 'girls', 'strategy', 'targeted', 'security'\n",
    "                   'as', 'seen', 'singles', 'own', 'opportunity', 'lifetime', 'work', 'at','from', 'home','easily', 'ads',\n",
    "                   'legal','here'] \n",
    "\n",
    "\n",
    "\n",
    "# Convert the emails to lower case as a first step to processing the text\n",
    "training['email'] = training['email'].str.lower()\n",
    "\n",
    "X_tr = pd.DataFrame(words_in_texts(some_other_words, training['email']))\n",
    "Y_tr = training['spam']\n",
    "\n",
    "X_tr[\"spesh chars\"] = spesh_char\n",
    "#X_tr[\"email length\"] = num_words_em\n",
    "#X_tr['subject length'] = num_words_sub\n",
    "X_tr['chars in email'] = chars_em\n",
    "X_tr['chars in sub'] = chars_sub\n",
    "X_tr['spesh chars'] = X_tr['spesh chars'].fillna(X_tr['spesh chars'].mean())\n",
    "#X_tr['email length'] = X_tr['email length'].fillna(X_tr['email length'].mean())\n",
    "#X_tr['subject length'] = X_tr['subject length'].fillna(X_tr['subject length'].mean())\n",
    "X_tr['# of uppercase in email'] = upper_em\n",
    "X_tr['reply?'] = replies\n",
    "#X_tr['forwrded?'] = forwards\n",
    "\n",
    "\n",
    "\n",
    "X_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9112205510448556\n",
      "Training Error (RMSE): 0.2979588041242353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "log_model =  LogisticRegression()\n",
    "log_model.fit(X_tr, Y_tr)\n",
    "\n",
    "tr_acc = log_model.score(X_tr, Y_tr)\n",
    "print(\"Training Accuracy: \", tr_acc)\n",
    "\n",
    "Y_tr_hat = log_model.predict(X_tr)\n",
    "\n",
    "\n",
    "def rmse(y, yhat):\n",
    "    return np.sqrt(np.mean((y - yhat)**2))\n",
    "\n",
    "print(\"Training Error (RMSE):\", rmse(Y_tr, Y_tr_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/srv/conda/envs/data100/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3111757856727273"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from lab 7\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def compute_CV_error(model, X_train, Y_train):\n",
    "    '''\n",
    "    Split the training data into 4 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the MSE on that subset (the validation set)\n",
    "    You should be fitting 4 models total.\n",
    "    Return the average MSE of these 4 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation MSE for the 4 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=10)\n",
    "    validation_errors = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = X_train.iloc[train_idx,:], X_train.iloc[valid_idx,:]\n",
    "        split_Y_train, split_Y_valid = Y_train.iloc[train_idx], Y_train.iloc[valid_idx]\n",
    "        # Fit the model on the training split\n",
    "        model.fit(split_X_train,split_Y_train)\n",
    "        \n",
    "        Y_hat = model.predict(split_X_valid)\n",
    "        \n",
    "        # Compute the RMSE on the validation split\n",
    "        error = rmse(split_Y_valid, model.predict(split_X_valid))\n",
    "        #error = log_loss(Y_hat, split_Y_valid, labels = [0,1])\n",
    "\n",
    "\n",
    "        validation_errors.append(error)\n",
    "        \n",
    "    return np.mean(validation_errors)\n",
    "compute_CV_error(log_model, X_tr, Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Feature/Model Selection Process\n",
    "\n",
    "In the following cell, describe the process of improving your model. You should use at least 2-3 sentences each to address the follow questions:\n",
    "\n",
    "1. How did you find better features for your model?\n",
    "2. What did you try that worked / didn't work?\n",
    "3. What was surprising in your search for good features?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7\n",
    "manual: True\n",
    "points: 6\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'applest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-503-234a53a52800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Number of words in the subject / body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnum_words_em\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'email'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mnum_words_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#Use of punctuation (e.g., how many '!' were there?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/data100/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'applest'"
     ]
    }
   ],
   "source": [
    "\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "test['subject'] = test[\"subject\"].apply(str)\n",
    "\n",
    "#1\n",
    "#Number of characters in the subject / body\n",
    "single_sub = [sub for sub in test['subject']]\n",
    "single_email = [sentence for sentence in test['email']]\n",
    "\n",
    "chars_em = [len(a) for a in single_email]\n",
    "chars_sub = [len(a) for a in single_sub]\n",
    "\n",
    "#Number of words in the subject / body\n",
    "num_words_em = test['email'].apply(len)\n",
    "num_words_sub = test['subject'].apply(len)\n",
    "\n",
    "#Use of punctuation (e.g., how many '!' were there?)\n",
    "spesh_char = test['email'].str.findall('[!&.?\":,|<>]').apply(len).astype(object)\n",
    "\n",
    "\n",
    "#Number / percentage of capital letters\n",
    "upper_em = [sum([c.isupper() for c in a]) for a in single_email]\n",
    "#upper_sub = [sum([c.isupper() for c in a]) for a in single_sub]\n",
    "\n",
    "\n",
    "#Whether the email is a reply to an earlier email or a forwarded email\n",
    "replies = []\n",
    "for sub in test[\"subject\"]:\n",
    "    if \"Re:\" in sub:\n",
    "        replies.append(1)\n",
    "    elif \"RE:\" in sub:\n",
    "        replies.append(1)\n",
    "    else:\n",
    "        replies.append(0)\n",
    "\n",
    "\n",
    "# Convert the emails to lower case as a first step to processing the text\n",
    "test['email'] = test['email'].str.lower()\n",
    "\n",
    "X_tst = pd.DataFrame(words_in_texts(some_other_words, test['email']))\n",
    "Y_tr = training['spam']\n",
    "\n",
    "X_tst[\"spesh chars\"] = spesh_char\n",
    "\n",
    "X_tst['chars in email'] = chars_em\n",
    "X_tst['chars in sub'] = chars_sub\n",
    "X_tst['spesh chars'] = X_tr['spesh chars'].fillna(X_tr['spesh chars'].mean())\n",
    "\n",
    "X_tst['# of uppercase in email'] = upper_em\n",
    "X_tst['reply?'] = replies\n",
    "\n",
    "test_predictions = log_model.predict(X_tst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
